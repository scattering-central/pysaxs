import os
from collections import OrderedDict
from distutils.dir_util import copy_tree
import shutil

import yaml

from .. import definitions as xrsdefs 
from .regressor import Regressor
from .classifier import Classifier

file_path = os.path.abspath(__file__)
models_dir = os.path.dirname(file_path)
package_dir = os.path.dirname(models_dir)
root_dir = os.path.dirname(package_dir)

# find directory containing packaged modeling data
modeling_data_dir = os.path.join(package_dir,'models','modeling_data')
regression_models_dir = os.path.join(modeling_data_dir,'regressors')
classification_models_dir = os.path.join(modeling_data_dir,'classifiers')

# find directory containing training summary
training_summary_yml = os.path.join(models_dir,'modeling_data','training_summary.yml')

def load_model_from_files(yml_file, pickle_file, model_class):
    """Build a xrsdkit Classifier from serialized model data.

    Parameters
    ----------
    yml_file : str
        absolute path to yml file generated by yaml.dump(cl.model.collect_model_data()) 
    pickle_file : str
        absolute path to pickle file generated by pickle.dump(cl.model) 
    model_class : str
        either 'classifier' or 'regressor'

    Returns
    -------
    modl : xrsdkit.models.xrsd_model.XRSDModel
        Either a xrsdkit Classifier or a xrsdkit Regressor,
        depending on the inputs provided
    """
    ymlf = open(yml_file,'rb')
    content = yaml.load(ymlf)
    ymlf.close()
    if model_class == 'classifier':
        modl = Classifier(content['model_type'],content['model_target'])
    elif model_class == 'regressor':
        modl = Regressor(content['model_type'],content['model_target'])
    else:
        raise ValueError('unrecognized model class: {}'.format(model_class))
    modl.load_model_data(content, pickle_file)
    return modl

def load_classification_models(model_root_dir=classification_models_dir):  
    model_dict = OrderedDict()
    if not os.path.exists(model_root_dir):
        return model_dict
    all_sys_cls = os.listdir(model_root_dir)
    # this next line filters out hidden files
    all_sys_cls = [i for i in all_sys_cls if not i[0]=='.']

    # the top-level classifier is a collection of classifiers;
    # their cumulative effect is to find the number of distinct populations
    # for each structure
    main_cls_path =  os.path.join(model_root_dir, 'main_classifiers')
    model_dict['main_classifiers'] = {}
    if os.path.exists(main_cls_path):
        all_main_cls = os.listdir(main_cls_path)
        # this next line filters out hidden files
        all_main_cls = [i for i in all_main_cls if not i[0]=='.']
        all_main_cls = [cl for cl in all_main_cls if cl.endswith('.yml')]
        for cl in all_main_cls:
            cl_name = os.path.splitext(cl)[0]
            yml_path = os.path.join(main_cls_path, cl)
            pickle_path =  os.path.join(main_cls_path, cl_name + '.pickle')
            model_dict['main_classifiers'][cl_name] = load_model_from_files(yml_path, pickle_path, 'classifier')

    if 'main_classifiers' in all_sys_cls: all_sys_cls.remove('main_classifiers')
    for sys_cls in all_sys_cls:
        model_dict[sys_cls] = {}
        sys_cls_dir = os.path.join(model_root_dir,sys_cls)
        noise_yml_path = os.path.join(sys_cls_dir,'noise_model.yml')
        if os.path.exists(noise_yml_path):
            pickle_path = os.path.join(sys_cls_dir,'noise_model.pickle')
            model_dict[sys_cls]['noise_model'] = load_model_from_files(noise_yml_path, pickle_path, 'classifier')

        for ipop,struct in enumerate(sys_cls.split('__')):
            pop_id = 'pop{}'.format(ipop)
            pop_dir = os.path.join(sys_cls_dir,pop_id)
            model_dict[sys_cls][pop_id] = {}

            # each population must have a form classifier
            form_yml_path = os.path.join(pop_dir,'form.yml')
            if os.path.exists(form_yml_path):
                pickle_path = os.path.join(pop_dir,'form.pickle')
                model_dict[sys_cls][pop_id]['form'] = load_model_from_files(form_yml_path, pickle_path, 'classifier')

            # other classifiers in this directory are for structure settings
            for stg_nm in xrsdefs.modelable_structure_settings[struct]:
                stg_yml_path = os.path.join(pop_dir,stg_nm+'.yml')
                if os.path.exists(stg_yml_path):
                    pickle_path = os.path.join(pop_dir,stg_nm+'.pickle')
                    model_dict[sys_cls][pop_id][stg_nm] = load_model_from_files(stg_yml_path, pickle_path, 'classifier')

            # some additional directories may exist for form factor settings-
            # these would be named according to their form factors
            for ffnm in xrsdefs.form_factor_names:
                ff_dir = os.path.join(pop_dir,ffnm)
                if os.path.exists(ff_dir):
                    model_dict[sys_cls][pop_id][ffnm] = {}
                    for stg_nm in xrsdefs.modelable_form_factor_settings[ffnm]:
                        stg_yml_path = os.path.join(ff_dir,stg_nm+'.yml')
                        if os.path.exists(stg_yml_path):
                            pickle_path = os.path.join(ff_dir,stg_nm+'.pickle')
                            model_dict[sys_cls][pop_id][ffnm][stg_nm] = load_model_from_files(stg_yml_path, pickle_path, 'classifier')
    return model_dict

def load_regression_models(model_root_dir=regression_models_dir):
    model_dict = OrderedDict()
    if not os.path.exists(model_root_dir):
        return model_dict

    all_sys_cls = os.listdir(model_root_dir)
    # this next line filters out hidden files
    all_sys_cls = [i for i in all_sys_cls if not i[0]=='.']
    for sys_cls in all_sys_cls:
        model_dict[sys_cls] = {}
        sys_cls_dir = os.path.join(model_root_dir,sys_cls)

        # every system class must have some noise parameters
        noise_dir = os.path.join(sys_cls_dir,'noise')
        model_dict[sys_cls]['noise'] = {}
        for modnm in xrsdefs.noise_model_names:
            noise_model_dir = os.path.join(noise_dir,modnm)
            if os.path.exists(noise_model_dir):
                model_dict[sys_cls]['noise'][modnm] = {}
                for pnm in list(xrsdefs.noise_params[modnm].keys())+['I0_fraction']:
                    param_yml_file = os.path.join(noise_model_dir,pnm+'.yml')
                    if os.path.exists(param_yml_file):
                        pickle_path = os.path.join(noise_model_dir,pnm+'.pickle')
                        model_dict[sys_cls]['noise'][modnm][pnm] = load_model_from_files(param_yml_file, pickle_path, 'regressor')

        for ipop,struct in enumerate(sys_cls.split('__')):
            pop_id = 'pop{}'.format(ipop)
            model_dict[sys_cls][pop_id] = {}
            pop_dir = os.path.join(sys_cls_dir,pop_id)

            # each population must have a model for its I0_fraction 
            I0_fraction_yml = os.path.join(pop_dir,'I0_fraction.yml')
            if os.path.exists(I0_fraction_yml):
                pickle_path = os.path.join(pop_dir,'I0_fraction.pickle')
                model_dict[sys_cls][pop_id]['I0_fraction'] = load_model_from_files(I0_fraction_yml, pickle_path, 'regressor')

            # each population may have additional parameters,
            # depending on settings
            for stg_nm in xrsdefs.modelable_structure_settings[struct]:
                stg_dir = os.path.join(pop_dir,stg_nm)
                if os.path.exists(stg_dir):
                    model_dict[sys_cls][pop_id][stg_nm] = {}
                    all_stg_labels = os.listdir(stg_dir)
                    # this next line filters out hidden files
                    all_stg_labels = [i for i in all_stg_labels if not i[0]=='.']
                    for stg_label in all_stg_labels:
                        stg_label_dir = os.path.join(stg_dir,stg_label)
                        if os.path.exists(stg_label_dir):
                            model_dict[sys_cls][pop_id][stg_nm][stg_label] = {}
                            for pnm in xrsdefs.structure_params(struct,{stg_nm:stg_label}):
                                param_yml = os.path.join(stg_label_dir,pnm+'.yml')
                                pickle_path = os.path.join(stg_label_dir,pnm+'.pickle')
                                model_dict[sys_cls][pop_id][stg_nm][stg_label][pnm] = load_model_from_files(param_yml, pickle_path, 'regressor')

            # each population may have still more parameters,
            # depending on the form factor selection
            for ff_nm in xrsdefs.form_factor_names:
                ff_dir = os.path.join(pop_dir,ff_nm)
                if os.path.exists(ff_dir):
                    model_dict[sys_cls][pop_id][ff_nm] = {}
                    for pnm in xrsdefs.form_factor_params[ff_nm]:
                        param_yml = os.path.join(ff_dir,pnm+'.yml')
                        pickle_path = os.path.join(ff_dir,pnm+'.pickle')
                        model_dict[sys_cls][pop_id][ff_nm][pnm] = load_model_from_files(param_yml, pickle_path, 'regressor')

                # the final layer of parameters depends on form factor settings
                for stg_nm in xrsdefs.modelable_form_factor_settings[ff_nm]:
                    stg_dir = os.path.join(ff_dir,stg_nm)
                    if os.path.exists(stg_dir): 
                        model_dict[sys_cls][pop_id][ff_nm][stg_nm] = {}
                        all_stg_labels = os.listdir(stg_dir)
                        # this next line filters out hidden files
                        all_stg_labels = [i for i in all_stg_labels if not i[0]=='.']
                        for stg_label in all_stg_labels:
                            stg_label_dir = os.path.join(stg_dir,stg_label)
                            if os.path.exists(stg_label_dir):
                                model_dict[sys_cls][pop_id][ff_nm][stg_nm][stg_label] = {}
                                for pnm in xrsdefs.additional_form_factor_params(ff_nm,{stg_nm:stg_label}):
                                    param_yml = os.path.join(stg_label_dir,pnm+'.yml')
                                    pickle_path = os.path.join(stg_label_dir,pnm+'.pickle')
                                    model_dict[sys_cls][pop_id][ff_nm][stg_nm][stg_label][pnm] = load_model_from_files(param_yml, pickle_path, 'regressor')
    return model_dict

_regression_models = load_regression_models(regression_models_dir)
_classification_models = load_classification_models(classification_models_dir)

def get_regression_models():
    return _regression_models

def get_classification_models():
    return _classification_models

def load_models(models_dir, modeling_data_dir):
   global _regression_models
   global _classification_models
   print('Loading models from '+models_dir)
   cl_dir = os.path.join(modeling_data_dir,'classifiers')
   reg_dir = os.path.join(modeling_data_dir,'regressors')
   summary = os.path.join(modeling_data_dir,'training_summary.yml')
   if os.path.isfile(cl_dir):
       shutil.rmtree(cl_dir)
   if os.path.isfile(reg_dir):
       shutil.rmtree(reg_dir)
   if os.path.isfile(summary):
       os.remove(summary)
   copy_tree(models_dir, modeling_data_dir)
   _regression_models = load_regression_models(reg_dir)
   _classification_models = load_classification_models(cl_dir)
   print("Done!")
