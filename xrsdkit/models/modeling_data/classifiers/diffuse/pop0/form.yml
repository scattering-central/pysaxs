cross_valid_results:
  F1_score_averaged_not_weighted: 0.9242997598189138
  F1_score_by_classes: [0.8712871287128713, 0.9773123909249564]
  accuracy: 0.9614243323442137
  all_classes: [spherical, guinier_porod]
  confusion_matrix: "[[ 44   0]\n [ 13 280]]"
  experiments: "['RxnH_201602' 'R2_201611' 'RxnB_201602' 'R4_201611' 'RxnC_201602'\n\
    \ 'R6_201611' 'RxnF_201602' 'R7_201611' 'R5_201611' 'RxnD_201602'\n 'RxnG_201602'\
    \ 'R1_201611' 'RxnA_201602' 'R0_201811' 'RxnE_201602']"
  number_of_experiments: 15
  test_training_split: "for classes with samples from 3 or more experiment_ids, \n\
    the data are split according to experiment_id; \nfor classes with samples from\
    \ 2 or fewer experiment_ids, \nthe data are randomly shuffled and split into three\
    \ groups"
default_val: null
model:
  hyper_parameters: {alpha: 1.0e-05, l1_ratio: 0.15}
  trained_par:
    classes_: [guinier_porod, spherical]
    coef_:
    - [-140.28812686552206, 152.9339303065821, -24.54431428667225, -27.636563086294906,
      -21.970108693265736, -15.37639242365142, -127.97725906646515, -136.62159323998426,
      8.526233169070876, 10.076164419816282, 31.263313097353954, 16.78998446133604,
      -4.394510046504812, -20.50886352644945, 80.9464505324945, 96.92896623572463,
      -130.48526238374927, -2.8078689977284172, -31.38084335009342, 218.68037024930615,
      -69.0746932504128]
    intercept_: [-196.36376145684181]
    t_: 1349.0
scaler:
  mean_: [3.9477962898246344, 2.2616886178547673, 1.1227170854699309, 4.202317143821649,
    4.413384265107162, 7.8750348875394875, 0.11070858358292907, 0.2402794971453952,
    0.48115050815637767, -0.6001587019357421, -0.5727039711202906, -0.5952160823559987,
    0.6019683768731601, 0.11185557373771014, 0.0922584456682079, 0.08730847263471142,
    0.18039618444620018, 0.09085682991445493, 0.11718661986777995, 0.013501945211669556,
    0.043648072147410004]
  scale_: [2.963315983023104, 1.7723539791579446, 0.15131986982202808, 3.182707838195595,
    2.453685379081054, 3.9973330274908756, 0.032452634871037646, 0.07444055548756286,
    4.3391134044937685, 0.1821785204179082, 0.16070425440076908, 0.17253103779530557,
    0.19447777465183533, 0.28110770114418493, 0.6954123059839928, 0.9158245615608295,
    1.8107082077045937, 0.184307508485177, 0.3786988288462398, 0.033481611005901184,
    0.2714072897871487]
trained: true
