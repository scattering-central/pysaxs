cross_valid_results:
  F1_score_averaged_not_weighted: 0.9801805337519622
  F1_score_by_classes: [0.9807692307692307, 0.9795918367346939]
  accuracy: 0.9801980198019802
  all_classes: [flat, low_q_scatter]
  confusion_matrix: "[[51  1]\n [ 1 48]]"
  experiments: '[''R5_201611'' ''R1_201611'' ''R4_201611'' ''R7_201611'' ''R6_201611'']'
  number_of_experiments: 5
  test_training_split: "for classes with samples from 3 or more experiment_ids, \n\
    the data are split according to experiment_id; \nfor classes with samples from\
    \ 2 or fewer experiment_ids, \nthe data are randomly shuffled and split into three\
    \ groups"
default_val: null
model:
  hyper_parameters: {alpha: 0.0001, l1_ratio: 1.0}
  trained_par:
    classes_: [flat, low_q_scatter]
    coef_:
    - [9.68582596097939, -23.03336165425586, 7.750723694345748, 21.467106219131043,
      -10.666696583816558, 23.639051036090233, 15.425881656585585, 27.871077422526366,
      -75.54071362865531, 17.264432481685912, 15.735955171090907, 16.93519932700359,
      -17.580187890246286, 6.575974887102245, -14.264996379304227, -21.274432857889597,
      -18.987549600940454, -40.26668075462734, -14.518058149465936, -71.8001061742887,
      35.926587241371415]
    intercept_: [-0.010135145986031402]
    t_: 809.0
scaler:
  mean_: [36.2396296126924, 5.478396572568196, 2.2052784739674918, 0.30303485386246837,
    5.015294662560045, 3.2395283895660625, 0.08957394403703346, 0.07457551541156078,
    -0.42914665994883866, -0.4215308730061589, -0.3225598437016715, -0.3935023368506325,
    0.44884739684138314, 0.05381520415228513, 0.09687362336110425, 0.006068434474921261,
    0.01999389820873166, 0.03493150458236377, 0.09882450522672666, 0.07409172683536891,
    0.003329040758798797]
  scale_: [21.167659211883812, 2.6552833304987393, 0.7851248031989074, 0.23905950146494637,
    0.8308064384910316, 0.49094297887570965, 0.015442167966104573, 0.016593828693671826,
    1.224195827025093, 0.1354529067627104, 0.09249602864879158, 0.12321560477782464,
    0.1482641430575905, 0.08837771677369212, 0.04662220914209993, 0.012503749465648724,
    0.014495661841027938, 0.2534156840060906, 0.044822705229141425, 0.31627994900584316,
    0.0014915469237066262]
trained: true
