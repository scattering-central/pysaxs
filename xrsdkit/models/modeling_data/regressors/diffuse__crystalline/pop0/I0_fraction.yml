cross_valid_results: {experiments: '[''R7_201611'' ''R6_201611'' ''R5_201611'' ''R1_201611''
    ''R4_201611'']', normalized_mean_abs_error: 0.21649062613407216, normalized_mean_abs_error_by_splits: '[0.3720931434552137,
    0.1628802199156887, 0.15637403389388083, 0.02752699049138875, 0.3635787429141888]',
  number_of_experiments: 5, test_training_split: by experiments, weighted_av_mean_abs_error: 0.1841704412819439}
default_val: null
model:
  hyper_parameters: {alpha: 1.0e-05, epsilon: 0.1, l1_ratio: 0.5}
  trained_par:
    coef_: [-0.026564233954581074, -0.010847479303033111, 0.04672058640803517, -0.008867368099048294,
      -0.0001185002748534131, -0.04516549222305846, 0.1557780464830845, -0.09915525031088111,
      0.11267375449330533, -0.08793451017087539, -0.08403485508605023, -0.08711947054826955,
      0.08872042422701779, -0.03677416865958598, 0.08943583238826551, 0.09274815051951714,
      0.11317773580611298, 0.010006165556652702, 0.08566047077004137, 0.052392463836143904,
      -0.06888226856333995]
    intercept_: [0.020774370298234816]
    t_: 5253.0
scaler:
  mean_: [36.2396296126924, 5.4783965725681965, 2.2052784739674918, 0.3030348538624684,
    5.015294662560045, 3.2395283895660625, 0.0895739440370335, 0.07457551541156077,
    -0.4291466599488386, -0.4215308730061588, -0.32255984370167146, -0.3935023368506325,
    0.4488473968413832, 0.053815204152285134, 0.09687362336110426, 0.0060684344749212605,
    0.019993898208731663, 0.034931504582363763, 0.09882450522672669, 0.07409172683536891,
    0.0033290407587987965]
  scale_: [21.16765921188381, 2.6552833304987393, 0.7851248031989074, 0.23905950146494634,
    0.8308064384910319, 0.49094297887570965, 0.015442167966104576, 0.01659382869367183,
    1.224195827025093, 0.13545290676271038, 0.09249602864879158, 0.12321560477782466,
    0.1482641430575905, 0.08837771677369212, 0.04662220914209993, 0.012503749465648726,
    0.014495661841027938, 0.2534156840060906, 0.04482270522914143, 0.31627994900584316,
    0.001491546923706626]
scaler_y:
  mean_: [0.5171450865931927]
  scale_: [0.49640938537126683]
trained: true
